{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Project 1- Iris Flower Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n",
      "   Petal-Length  Petal-Width  Sepal-Length  Saple-Width       Target\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('iris_csds.csv',header=None)\n",
    "df.columns=['Petal-Length','Petal-Width','Sepal-Length','Saple-Width','Target']\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Petal-Length  150 non-null    float64\n",
      " 1   Petal-Width   150 non-null    float64\n",
      " 2   Sepal-Length  150 non-null    float64\n",
      " 3   Saple-Width   150 non-null    float64\n",
      " 4   Target        150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "Iris-setosa        50\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'Iris-setosa':0,'Iris-versicolor':1,'Iris-virginica':2}\n",
    "df1=df\n",
    "df1['Target']=df1['Target'].map(dict)\n",
    "df1['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data=load_iris()\n",
    "x=data.data\n",
    "y=data.target\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print((y==0).sum())\n",
    "import numpy as np\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(105, 4)\n",
      "(45, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,\n",
    "                                              random_state=0)\n",
    "print(x.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf=Perceptron()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.8952380952380953\n",
      "Testing Acc= 0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print((y_test!=y_test_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cr=classification_report(y_test,y_test_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 2  9  7]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_test_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD4CAYAAADM6gxlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAM10lEQVR4nO3ae5DVdRnH8c9z9qLcREtg2QXDxPEyojIiM4WakYoaCtpEmthUGllqMmNaFnYZE6wxHUktSUtNQahUFLEYyyLLy4IR9xDYFXZZMBSUFYvdw9Mf7DBeYPecs5z97sO+XzPMcH5nnPOZ+cLbH7895u4CAMSRST0AAJAfwg0AwRBuAAiGcANAMIQbAIIpLfYHNG1ey9dWgupWeWrqCUCX1byj3vb2HnfcABAM4QaAYAg3AARDuAEgGMINAMEQbgAIhnADQDCEGwCCIdwAEAzhBoBgCDcABEO4ASAYwg0AwRBuAAiGcANAMIQbAIIh3AAQDOEGgGAINwAEQ7gBIBjCDQDBEG4ACIZwA0AwhBsAgiHcABAM4QaAYAg3AARDuAEgGMINAMEQbgAIhnADQDCEOw+TJt+m0z59kcaOv+I91x/+7WyNvuhyjbnkq/rpXfclWod8jDrrdC1bOl8rlz+n66+7MvUc5Kmrn19p6gGRjD33TH3+M+frOzfduvvaSwv/pWefe0GPPni3ysvL9fqWrekGIieZTEZT77hZZ597serqGvTC83P15Jx5WrHildTTkAPOjzvuvAw7cYh6H9TrPddmPv6ULhs/TuXl5ZKkDx9ycIJlyMfwk4dqzZpa1dSsU1NTk2bNmq3zzxuVehZyxPnlcMdtZkdLGiOpSpJL2iDpCXdfUeRtIdSuq9fCfy3V1GkP6IDyMl171eUacsxRqWehFZVVFVpft2H367r6Bg0/eWjCRcgH59fGHbeZfUvSI5JM0kuSqlt+P8PMvl38eZ1fNpvVW9saNX3a7br2ysv1zRunyN1Tz0IrzOwD1zizODi/th+VXCbpZHe/xd0favl1i6ThLe/tkZlNMLMFZrbg3gdn7Mu9nU6/vofqjE+MkJlpyLFHycy0ZeubqWehFfV1DRo4oHL36wFV/dXQsCnhIuSD82s73DslVe7hev+W9/bI3ae5+zB3H3b5Fy5uz75Ob+SpH9NLCxdJkmrX1ampuVmHHNw77Si0qnrBIg0efLgGDRqosrIyjRs3Rk/OmZd6FnLE+bX9jHuipD+Z2SuS1rdcO0zSYElXFXFXp3Td929R9T8Xa+vWt/SpseP19csu1YWjz9Kkybdr7PgrVFZWqsmTrt3jP+XQeWSzWV0zcZLmPjVdJZmM7n9gppYvX5V6FnLE+UnW1rMhM8to16ORKu16vl0nqdrds7l8QNPmtV3r4dN+pFvlqaknAF1W8476vd4BtvmtEnffKemFfboIAFAwvscNAMEQbgAIhnADQDCEGwCCIdwAEAzhBoBgCDcABEO4ASAYwg0AwRBuAAiGcANAMIQbAIIh3AAQDOEGgGAINwAEQ7gBIBjCDQDBEG4ACIZwA0AwhBsAgiHcABAM4QaAYAg3AARDuAEgGMINAMEQbgAIhnADQDCEGwCCIdwAEAzhBoBgSov9AcOPu7TYH4EiWX3ssaknoB2WbDw09QQUCXfcABAM4QaAYAg3AARDuAEgGMINAMEQbgAIhnADQDCEGwCCIdwAEAzhBoBgCDcABEO4ASAYwg0AwRBuAAiGcANAMIQbAIIh3AAQDOEGgGAINwAEQ7gBIBjCDQDBEG4ACIZwA0AwhBsAgiHcABAM4QaAYAg3AARDuAEgGMINAMEQbgAIhnADQDCEGwCCKU09IKp+lX11089u1If7fEjurt//ZrZm3Pvb1LOQo16fv0C9LjxHMlPjo3P11sOPpZ6EHPU4or9Ouucbu193/0hf/fsnv1PNL59OuKpjEe4CZZuzuu0HP9PKJavUvUd3TZ93n16cX621q2pTT0Mbyo4YpF4XnqOG8VfLm5rU764p2v63l9S8rj71NOTg7TUNmn/GDbteZExnLrpbG5+uTjuqg/GopECbX3tdK5eskiRtf3u7al55VX0q+iRehVyUffQw/W/xSvl//ydld+q/Cxer+8gRqWehAH1OPU7bazfpnbrNqad0qILDbWZf2pdDIus/sEJHHXeklr68LPUU5KBpda0OPGmIMr17yQ48QN1OGa7SfvxPN6LKsR9X/eP/SD2jw7XnjvuHe3vDzCaY2QIzW7B5+8Z2fETn1617N91678269XtT9Xbj9tRzkIOmmnV689cz1e8XP1a/uyaradVaeTabehbyZGUlqjjrJG144sXUUzpcq8+4zWzx3t6S1G9v/527T5M0TZKGVozwgtd1cqWlJbr1vpv19KPz9Oe5f009B3lofPwPanz8D5Kkg6/+srKb/pN4EfLVd+SJenNJjXZsfjP1lA7X1g8n+0kaJWnL+66bpK7375P3+f7tN6jmlVf10D0zU09BnjKHHKydW7aqpKKPeowcoYYvXJN6EvJUdUHXfEwitR3uOZJ6uvui979hZn8pxqAoThx+vEZ/9hytWr5ajzxzvyTpzin36Lk/PZ92GHLS96ffU6b3QVJzs16fcqd2bmtMPQl5KOlWrj6nDdHi6+5NPSUJcy/uk4z9+VHJ/u6xiu6pJ6Adlmw8NPUEtMN5G2fY3t7j64AAEAzhBoBgCDcABEO4ASAYwg0AwRBuAAiGcANAMIQbAIIh3AAQDOEGgGAINwAEQ7gBIBjCDQDBEG4ACIZwA0AwhBsAgiHcABAM4QaAYAg3AARDuAEgGMINAMEQbgAIhnADQDCEGwCCIdwAEAzhBoBgCDcABEO4ASAYwg0AwRBuAAiGcANAMKXF/oAlb9QW+yNQJIPfSL0A7bFlwgmpJ6BIuOMGgGAINwAEQ7gBIBjCDQDBEG4ACIZwA0AwhBsAgiHcABAM4QaAYAg3AARDuAEgGMINAMEQbgAIhnADQDCEGwCCIdwAEAzhBoBgCDcABEO4ASAYwg0AwRBuAAiGcANAMIQbAIIh3AAQDOEGgGAINwAEQ7gBIBjCDQDBEG4ACIZwA0AwhBsAgiHcBRp11ulatnS+Vi5/Ttdfd2XqOcgT5xfLgZdMVI8p09X9O3fvvlY69BR1/+7P1XPqHGUOOzLhuo5HuAuQyWQ09Y6bNfq88Rpywif1uc+N1THHdK0/OJFxfvE0vfCM3rnrxvdc27nhVb3zyx8pu2ZpolXpEO4CDD95qNasqVVNzTo1NTVp1qzZOv+8UalnIUecXzzZNUvl27e959rOTevlr9UnWpRWm+E2s6PN7FNm1vN9188u3qzOrbKqQuvrNux+XVffoMrKioSLkA/OD9G1Gm4z+4ak2ZKulrTUzMa86+3JxRzWmZnZB665e4IlKATnh+hK23j/K5JOcvdGMxsk6XdmNsjd75D0wT/9LcxsgqQJkmQlvZXJ9NhXezuF+roGDRxQufv1gKr+amjYlHAR8sH5Ibq2HpWUuHujJLl7raTTJZ1jZreplXC7+zR3H+buw/a3aEtS9YJFGjz4cA0aNFBlZWUaN26MnpwzL/Us5IjzQ3Rt3XFvNLMT3X2RJLXceY+W9CtJQ4o9rrPKZrO6ZuIkzX1qukoyGd3/wEwtX74q9SzkiPOL58AvXq+SI4+X9TxIPW56UDvmPiR/e5sO+OzXZD17q9sVP9DO+rUf+ObJ/spae7ZnZgMkNbv7xj28N8Ld/97WB5SWV/HwEEhgy4QTUk9AO/S6c+5en2q0esft7nWtvNdmtAEA+x7f4waAYAg3AARDuAEgGMINAMEQbgAIhnADQDCEGwCCIdwAEAzhBoBgCDcABEO4ASAYwg0AwRBuAAiGcANAMIQbAIIh3AAQDOEGgGAINwAEQ7gBIBjCDQDBEG4ACIZwA0AwhBsAgiHcABAM4QaAYAg3AARDuAEgGMINAMEQbgAIhnADQDCEGwCCMXdPvSE0M5vg7tNS70BhOL+4uvLZccfdfhNSD0C7cH5xddmzI9wAEAzhBoBgCHf7dclnbPsRzi+uLnt2/HASAILhjhsAgiHcABAM4S6QmZ1tZv82s9Vm9u3Ue5AfM/uVmb1mZktTb0F+zGygmT1rZivMbJmZXZN6U0fjGXcBzKxE0ipJZ0qqk1Qt6WJ3X550GHJmZqdJapT0oLsfl3oPcmdm/SX1d/eXzayXpIWSxnalv3/ccRdmuKTV7r7W3XdIekTSmMSbkAd3ny/pjdQ7kD93b3D3l1t+v03SCklVaVd1LMJdmCpJ69/1uk5d7A8O0BmY2SBJQyW9mHhKhyLchbE9XOOZE9CBzKynpN9Lmujub6Xe05EId2HqJA181+sBkjYk2gJ0OWZWpl3RftjdH029p6MR7sJUSzrSzA43s3JJF0l6IvEmoEswM5N0n6QV7n5b6j0pEO4CuHuzpKsk/VG7fjAyy92XpV2FfJjZDEnPSzrKzOrM7LLUm5CzEZIulTTSzBa1/Do39aiOxNcBASAY7rgBIBjCDQDBEG4ACIZwA0AwhBsAgiHcABAM4QaAYP4PPQZDttnwCPwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cm,annot=True,cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.9809523809523809\n",
      "Testing Acc= 0.9777777777777777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lakshita\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.9714285714285714\n",
      "Testing Acc= 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "from sklearn.svm import SVC\n",
    "clf=SVC()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.9714285714285714\n",
      "Testing Acc= 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf=KNeighborsClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the performance of different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6bc7071333f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron,LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier,AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,VotingClassifier\n",
    "clf1=Perceptron()\n",
    "clf2=LogisticRegression()\n",
    "clf3=SVC()\n",
    "clf4=KNeighborsClassifier()\n",
    "clf5=GaussianNB()\n",
    "clf6=DecisionTreeClassifier()\n",
    "clf7=RandomForestClassifier()\n",
    "clf8=BaggingClassifier()\n",
    "clf9=ExtraTreesClassifier()\n",
    "clf10=AdaBoostClassifier()\n",
    "clf11=GradientBoostingClassifier()\n",
    "clf12=VotingClassifier(estimators=[('per',clf1),('dt',clf6),('ada',clf10)],\n",
    "                      voting='hard')\n",
    "clf=[clf1,clf2,clf3,clf4,clf5,clf6,clf7,clf8,clf9,clf10,clf11,clf12]\n",
    "name=['Per','LR','SVC','KNN','GNB','DT','RF','BAG','ET','ADA','GBC','VT']\n",
    "accuracy={}\n",
    "for model,model_name in zip(clf,name):\n",
    "    model.fit(x_train,y_train)\n",
    "    acc=accuracy_score(model.predict(x_test),y_test)\n",
    "    accuracy[model_name]=acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per : 0.8\n",
      "LR : 0.9777777777777777\n",
      "SVC : 0.9777777777777777\n",
      "KNN : 0.9777777777777777\n",
      "GNB : 1.0\n",
      "DT : 0.9777777777777777\n",
      "RF : 0.9777777777777777\n",
      "BAG : 0.9777777777777777\n",
      "ET : 0.9777777777777777\n",
      "ADA : 0.9111111111111111\n",
      "GBC : 0.9777777777777777\n",
      "VT : 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "for i,j in accuracy.items():\n",
    "    print(i,':',j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
